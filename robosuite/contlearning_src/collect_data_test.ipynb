{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "['', '/home/puresulfur/OneDrive/PyCharm_Server_Files/ContLearning_proj/NewBaxterPush-master/robosuite/robosuite/continual_learning', '/home/puresulfur/OneDrive/PyCharm_Server_Files/ContLearning_proj/NewBaxterPush-master/robosuite', '/home/puresulfur/anaconda3/envs/robosuite/lib/python36.zip', '/home/puresulfur/anaconda3/envs/robosuite/lib/python3.6', '/home/puresulfur/anaconda3/envs/robosuite/lib/python3.6/lib-dynload', '/home/puresulfur/.local/lib/python3.6/site-packages', '/home/puresulfur/anaconda3/envs/robosuite/lib/python3.6/site-packages', '/home/puresulfur/anaconda3/envs/robosuite/lib/python3.6/site-packages/IPython/extensions', '/home/puresulfur/.ipython', '/home/puresulfur/anaconda3/envs/robosuite/lib/python3.6/site-packages/robosuite-0.1.0-py3.6.egg']\n"
     ]
    }
   ],
   "source": [
    "# %run -i '/home/puresulfur/OneDrive/PyCharm_Server_Files/ContLearning_proj/NewBaxterPush-master/robosuite/robosuite/continual_learning/collect_data_1.py' --render True --task pick\n",
    "# python /home/puresulfur/OneDrive/PyCharm_Server_Files/ContLearning_proj/NewBaxterPush-master/robosuite/robosuite/continual_learning/collect_data_1.py --render True --task pick\n",
    "# !python '/home/puresulfur/OneDrive/PyCharm_Server_Files/ContLearning_proj/NewBaxterPush-master/robosuite/robosuite/continual_learning/collect_data_1.py --render True --task pick'\n",
    "import os,sys\n",
    "# from behavior_cloning import * #SimpleCNN\n",
    "FILE_PATH = os.path.abspath(\n",
    "    '/home/puresulfur/OneDrive/PyCharm_Server_Files/ContLearning_proj/NewBaxterPush-master/robosuite/robosuite')\n",
    "sys.path.append('/home/puresulfur/anaconda3/envs/robosuite/lib/python3.6/site-packages/robosuite-0.1.0-py3.6.egg')\n",
    "# sys.path.insert(0, os.path.join(FILE_PATH, 'continual_learning'))\n",
    "# sys.path.append(os.path.join(FILE_PATH, 'continual_learning'))\n",
    "# sys.path.append(os.path.join(FILE_PATH, 'IL'))\n",
    "# sys.path.append(os.path.join(FILE_PATH, 'scripts'))\n",
    "# sys.path.append(os.path.join(FILE_PATH, 'wrappers'))\n",
    "print(9+10)\n",
    "import pickle\n",
    "# import tensorflow as tf\n",
    "import argparse\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import shutil\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make('FetchPush-v1')\n",
    "env.reset()\n",
    "for _ in range(1000):\n",
    "  env.render()\n",
    "  env.step(env.action_space.sample()) # take a random action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym.wrappers import Monitor\n",
    "\n",
    "env = gym.make('HalfCheetah-v2')\n",
    "env = Monitor(env, './video', force=True)\n",
    "env.reset()\n",
    "while True:\n",
    "    obs, r, done, info = env.step([0, 0, 0, 0, 0, 0])\n",
    "    if done: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-70e2e4e95467>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "\n",
    "for _ in range(100):\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    action = env.action_space.sample()\n",
    "    env.step(action)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%run -i '/home/puresulfur/OneDrive/PyCharm_Server_Files/ContLearning_proj/NewBaxterPush-master/robosuite/robosuite/continual_learning/collect_data_1.py' --render True --task pick\n",
    "# python /home/puresulfur/OneDrive/PyCharm_Server_Files/ContLearning_proj/NewBaxterPush-master/robosuite/robosuite/continual_learning/collect_data_1.py --render True --task pick\n",
    "# !python '/home/puresulfur/OneDrive/PyCharm_Server_Files/ContLearning_proj/NewBaxterPush-master/robosuite/robosuite/continual_learning/collect_data_1.py --render True --task pick'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i '/home/puresulfur/OneDrive/PyCharm_Server_Files/ContLearning_proj/NewBaxterPush-master/robosuite/robosuite/continual_learning/collect_data_1.py' --render True --task pick\n",
    "# python /home/puresulfur/OneDrive/PyCharm_Server_Files/ContLearning_proj/NewBaxterPush-master/robosuite/robosuite/continual_learning/collect_data_1.py --render True --task pick\n",
    "# !python '/home/puresulfur/OneDrive/PyCharm_Server_Files/ContLearning_proj/NewBaxterPush-master/robosuite/robosuite/continual_learning/collect_data_1.py --render True --task pick'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from class_import_test import abba\n",
    "# about = abba()\n",
    "# about.change_a(12)\n",
    "# print(about.a)\n",
    "\n",
    "\n",
    "import os,sys\n",
    "# print(sys.path)\n",
    "import mujoco_py\n",
    "FILE_PATH = os.path.abspath('/home/puresulfur/OneDrive/PyCharm_Server_Files/ContLearning_proj/NewBaxterPush-master/robosuite/robosuite')\n",
    "# sys.path.append(os.path.join(FILE_PATH, 'robosuite/IL'))\n",
    "# sys.path.append(os.path.join(FILE_PATH, 'scripts'))\n",
    "# sys.path.append(os.path.join(FILE_PATH, 'wrappers'))\n",
    "# from robosuite.wrappers import IKWrapper\n",
    "\n",
    "import robosuite\n",
    "# from ik_wrapper import IKWrapper\n",
    "# from cont_learning_picking import BaxterTestingEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "DependencyNotInstalled",
     "evalue": "Found neither the ffmpeg nor avconv executables. On OS X, you can install ffmpeg via `brew install ffmpeg`. On most Ubuntu variants, `sudo apt-get install ffmpeg` should do it. On Ubuntu 14.04, however, you'll need to install avconv with `sudo apt-get install libav-tools`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDependencyNotInstalled\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2cf5c9043450>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SpaceInvaders-v0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMonitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./gym-results\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/robosuite/lib/python3.6/site-packages/gym/wrappers/monitor.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/robosuite/lib/python3.6/site-packages/gym/wrappers/monitor.py\u001b[0m in \u001b[0;36m_after_reset\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats_recorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_video_recorder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;31m# Bump *after* all reset activity has finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/robosuite/lib/python3.6/site-packages/gym/wrappers/monitor.py\u001b[0m in \u001b[0;36mreset_video_recorder\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_video_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         )\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo_recorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_close_video_recorder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/robosuite/lib/python3.6/site-packages/gym/wrappers/monitoring/video_recorder.py\u001b[0m in \u001b[0;36mcapture_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encode_ansi_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encode_image_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/robosuite/lib/python3.6/site-packages/gym/wrappers/monitoring/video_recorder.py\u001b[0m in \u001b[0;36m_encode_image_frame\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_encode_image_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframes_per_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoder_version'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/robosuite/lib/python3.6/site-packages/gym/wrappers/monitoring/video_recorder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, output_path, frame_shape, frames_per_sec)\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ffmpeg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDependencyNotInstalled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\"Found neither the ffmpeg nor avconv executables. On OS X, you can install ffmpeg via `brew install ffmpeg`. On most Ubuntu variants, `sudo apt-get install ffmpeg` should do it. On Ubuntu 14.04, however, you'll need to install avconv with `sudo apt-get install libav-tools`.\"\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDependencyNotInstalled\u001b[0m: Found neither the ffmpeg nor avconv executables. On OS X, you can install ffmpeg via `brew install ffmpeg`. On most Ubuntu variants, `sudo apt-get install ffmpeg` should do it. On Ubuntu 14.04, however, you'll need to install avconv with `sudo apt-get install libav-tools`."
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym import wrappers\n",
    "\n",
    "env = gym.make('SpaceInvaders-v0')\n",
    "env = wrappers.Monitor(env, \"./gym-results\", force=True)\n",
    "env.reset()\n",
    "for _ in range(1000):\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    if done: break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'argparse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-07cbf7164c3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#argument parsing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArgumentParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--render'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--num-episodes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--use_feature'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'argparse' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#argument parsing\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--render', type=bool, default=False)\n",
    "parser.add_argument('--num-episodes', type=int, default=10000)\n",
    "parser.add_argument('--use_feature', type=int, default=0)\n",
    "parser.add_argument('--task', type=str, default=\"pick\")\n",
    "parser.add_argument('--action_type', type=str, default=\"2D\")\n",
    "parser.add_argument('--random_spawn', type=int, default=0)\n",
    "parser.add_argument('--small_cube', type=int, default=1)\n",
    "parser.add_argument('--num-blocks', type=int, default=1)\n",
    "parser.add_argument('--save_data', type=int, default=1)\n",
    "parser.add_argument('--max_buff', type=int, default=5) #512\n",
    "\n",
    "# camera resolution\n",
    "screen_width = 192 #64\n",
    "screen_height = 192 #64\n",
    "crop = 128 #None\n",
    "\n",
    "# Path which data will be saved in.\n",
    "save_name = os.path.join(FILE_PATH, 'data')\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # GPU is not efficient here\n",
    "\n",
    "data = np.random.random((100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class GreedyAgent():\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self.task = self.env.task\n",
    "        # self.using_feature = self.env.using_feature\n",
    "        self.mov_dist = self.env.mov_dist\n",
    "        self.action_size = self.env.action_size\n",
    "        self.action_type = self.env.action_type\n",
    "\n",
    "    def get_action(self, obs):\n",
    "        mov_dist = self.mov_dist\n",
    "        if self.task == 'reach':\n",
    "            predicted_distance_list = []\n",
    "            for action in range(self.action_size):\n",
    "                if action < 8:\n",
    "                    mov_degree = action * np.pi / 4.0\n",
    "                    arm_pos = self.env.arm_pos + np.array([mov_dist* np.cos(mov_degree),\n",
    "                                                           mov_dist * np.sin(mov_degree),\n",
    "                                                           0.0])\n",
    "                elif action == 8:\n",
    "                    arm_pos = self.env.arm_pos + np.array([0.0, 0.0, mov_dist])\n",
    "                elif action == 9:\n",
    "                    arm_pos = self.env.arm_pos + np.array([0.0, 0.0, -mov_dist])\n",
    "\n",
    "                if arm_pos[2] < 0.57:\n",
    "                    predicted_distance_list.append(np.inf)\n",
    "                else:\n",
    "                    dist = np.linalg.norm(arm_pos - self.env.obj_pos)\n",
    "                    predicted_distance_list.append(dist)\n",
    "\n",
    "            action = np.argmin(predicted_distance_list)\n",
    "\n",
    "        elif self.task == 'push':\n",
    "            if self.action_type=='2D':\n",
    "                vec_target_obj = self.env.target_pos - self.env.obj_pos\n",
    "                vec_obj_arm = self.env.obj_pos - self.env.arm_pos\n",
    "                mov_vec_list = []\n",
    "                for a in range(8):\n",
    "                    mov_degree = a * np.pi / 4.0\n",
    "                    mov_vec_list.append(np.array([mov_dist * np.cos(mov_degree),\n",
    "                                                  mov_dist * np.sin(mov_degree)]))\n",
    "                mov_cos_list = [self.get_cos(v, vec_obj_arm[:2]) for v in mov_vec_list]\n",
    "\n",
    "                pred_vec_target_obj = vec_target_obj \\\n",
    "                                      - self.mov_dist * vec_obj_arm \\\n",
    "                                      / np.linalg.norm(vec_obj_arm)\n",
    "\n",
    "                theta_threshold = np.pi/5 \\\n",
    "                    if np.linalg.norm(vec_target_obj[:2])>0.10 \\\n",
    "                    else np.pi/3\n",
    "                if self.get_cos(pred_vec_target_obj[:2],\n",
    "                                vec_obj_arm[:2]) > np.cos(theta_threshold):  # > 0\n",
    "                    action = np.argmax(mov_cos_list)\n",
    "                else:\n",
    "                    mov_cos_list = [self.get_cos(v, vec_target_obj[:2]) for v in mov_vec_list]\n",
    "                    action = np.argmax(mov_cos_list)\n",
    "                    '''\n",
    "                    next_obj_arm = [vec_obj_arm[:2] - v for v in mov_vec_list]\n",
    "                    next_cos_list = [self.get_cos(vec_target_obj[:2], w) for w in next_obj_arm]\n",
    "                    action = np.argmax(next_cos_list)\n",
    "                    ## to avoid repetition ##\n",
    "                    if (action+4)%8 == np.argmax(mov_cos_list):\n",
    "                        next_cos_list[action] = -1.0\n",
    "                        action = np.argmax(next_cos_list)\n",
    "                    '''\n",
    "\n",
    "            elif self.action_type=='3D':\n",
    "                vec_target_obj = self.env.target_pos - self.env.obj_pos\n",
    "                vec_obj_arm = self.env.obj_pos - self.env.arm_pos\n",
    "                mov_vec_list = []\n",
    "                for a in range(8):\n",
    "                    mov_degree = a * np.pi / 4.0\n",
    "                    mov_vec_list.append(np.array([mov_dist * np.cos(mov_degree),\n",
    "                                                  mov_dist * np.sin(mov_degree)]))\n",
    "                    # elif a == 8:\n",
    "                    #     mov_vec_list.append(np.array([0.0, 0.0, mov_dist]))\n",
    "                    # elif a == 9:\n",
    "                    #     mov_vec_list.append(np.array([0.0, 0.0, -mov_dist]))\n",
    "                mov_cos_list = [self.get_cos(v, vec_obj_arm[:2]) for v in mov_vec_list]\n",
    "\n",
    "                if self.get_cos(vec_target_obj[:2], vec_obj_arm[:2]) > 0:\n",
    "                    if self.env.arm_pos[2] < 0.65:\n",
    "                        action = np.argmax(mov_cos_list)\n",
    "                    else:\n",
    "                        if np.linalg.norm(vec_obj_arm) > 2.0 * mov_dist:\n",
    "                            action = 9\n",
    "                        else:\n",
    "                            next_obj_arm = [vec_obj_arm[:2] - v for v in mov_vec_list]\n",
    "                            next_cos_list = [self.get_cos(vec_target_obj[:2], w)\n",
    "                                             for w in next_obj_arm]\n",
    "                            action = np.argmax(next_cos_list)\n",
    "                            '''\n",
    "                            best_a = np.argmax(mov_cos_list)\n",
    "                            mov_cos_list[best_a] = np.min(mov_cos_list)\n",
    "                            next_best_a = np.argmax(mov_cos_list)\n",
    "                            if self.get_cos(mov_vec_list[best_a][:2], vec_target_obj[:2]) > 0:\n",
    "                                action = best_a\n",
    "                            else:\n",
    "                                action = next_best_a\n",
    "                            action = (action + 4) % 8\n",
    "                            '''\n",
    "                else:\n",
    "                    if self.env.arm_pos[2] < 0.65:\n",
    "                        action = 8\n",
    "                    else:\n",
    "                        next_obj_arm = [vec_obj_arm[:2] - v for v in mov_vec_list]\n",
    "                        next_cos_list = [self.get_cos(vec_target_obj[:2], w)\n",
    "                                         for w in next_obj_arm]\n",
    "                        action = np.argmax(next_cos_list)\n",
    "\n",
    "        # greedy agent for pick\n",
    "        elif self.task=='pick':\n",
    "            curr_arm_pos = self.env.arm_pos\n",
    "            dist = np.linalg.norm(curr_arm_pos[:2] - self.env.obj_pos[:2])\n",
    "\n",
    "            ## move to Pick ## -> if far away, try all moves and pick the best one\n",
    "            if dist > mov_dist / 2:\n",
    "                predicted_distance_list = []\n",
    "                for action in range(8):\n",
    "                    mov_degree = action * np.pi / 4.0\n",
    "                    arm_pos = curr_arm_pos + np.array(\n",
    "                        [mov_dist * np.cos(mov_degree),\n",
    "                         mov_dist * np.sin(mov_degree),\n",
    "                         0.0])\n",
    "                    predicted_dist = np.linalg.norm(arm_pos - self.env.obj_pos)\n",
    "                    predicted_distance_list.append(predicted_dist)\n",
    "                action = np.argmin(predicted_distance_list)\n",
    "            ## move down ##\n",
    "            elif self.env.grasp == 0.0:\n",
    "                if curr_arm_pos[2] - self.env.obj_pos[2] > 0:  # mov_dist:\n",
    "                    action = 9\n",
    "                    # if self.env.fix_stuck and bool(1 - self.env.grasp):\n",
    "                    #     print(\"move up to fix the gripper\")\n",
    "                    #     # self.env.pre_obj_pos = self.env.obj_pos\n",
    "                    #     self.env.fix_stuck = False\n",
    "                    #     action = 8\n",
    "                    # else :\n",
    "                    #     action = 9\n",
    "                ## Pick ##\n",
    "                else:\n",
    "                    action = 10\n",
    "            ## move up ##\n",
    "            elif self.env.grasp == 1.0:\n",
    "                action = 8\n",
    "\n",
    "        elif self.task=='place':\n",
    "            if np.linalg.norm(self.env.obj_pos[:2]\n",
    "                              - self.env.target_pos[:2]) > mov_dist / 2:\n",
    "                curr_arm_pos = self.env.arm_pos\n",
    "                predicted_distance_list = []\n",
    "                for action in range(8):\n",
    "                    mov_degree = action * np.pi / 4.0\n",
    "                    arm_pos = curr_arm_pos + np.array(\n",
    "                        [mov_dist * np.cos(mov_degree),\n",
    "                         mov_dist * np.sin(mov_degree), 0.0])\n",
    "                    predicted_dist = np.linalg.norm(arm_pos - self.env.target_pos)\n",
    "                    predicted_distance_list.append(predicted_dist)\n",
    "                action = np.argmin(predicted_distance_list)\n",
    "            else:\n",
    "                action = 9\n",
    "\n",
    "        return action\n",
    "\n",
    "    def get_cos(self, vec1, vec2):\n",
    "        return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "FLAGS = parser.parse_args()\n",
    "    print(FLAGS.render)\n",
    "    using_feature = bool(FLAGS.use_feature)\n",
    "    if using_feature:\n",
    "        print('This agent will use feature-based states..!!')\n",
    "    else:\n",
    "        print('This agent will use image-based states..!!')\n",
    "    render = bool(FLAGS.render)\n",
    "    save_data = bool(FLAGS.save_data)\n",
    "    print_on = False\n",
    "    task = FLAGS.task\n",
    "    action_type = FLAGS.action_type\n",
    "    random_spawn = bool(FLAGS.random_spawn)\n",
    "    use_small_cube = bool(FLAGS.small_cube)\n",
    "    num_blocks = FLAGS.num_blocks\n",
    "\n",
    "    object_type = 'smallcube' if use_small_cube else 'cube' #if task=='pick' or task=='place' else 'cube'\n",
    "    print(\"IN collect_data_1.py: now making BaxterPush class\")\n",
    "    env = robosuite.make(\n",
    "        \"BaxterPush\",\n",
    "        bin_type='table',\n",
    "        object_type=object_type,\n",
    "        ignore_done=True,\n",
    "        has_renderer=True,\n",
    "        camera_name=\"eye_on_right_wrist\",\n",
    "        gripper_visualization=False,\n",
    "        use_camera_obs=False,\n",
    "        use_object_obs=False,\n",
    "        camera_depth=True,\n",
    "        num_objects=num_blocks,\n",
    "        control_freq=100,\n",
    "        camera_width=screen_width,\n",
    "        camera_height=screen_height,\n",
    "        crop=crop\n",
    "    )\n",
    "    print(\"IN collect_data_1.py: just made BaxterPush class\")\n",
    "    print(\"IN collect_data_1.py: making IKWrapper around the env\")\n",
    "    env = IKWrapper(env)\n",
    "    print(\"IN collect_data_1.py: just made IKWrapper around the env\")\n",
    "\n",
    "    print(\"IN collect_data_1.py: making BaxterTestingEnv with env\")\n",
    "    env = BaxterTestingEnv(env, task=task, render=render,\n",
    "                    using_feature=using_feature,\n",
    "                    random_spawn=random_spawn,\n",
    "                    rgbd=True, action_type=action_type)\n",
    "\n",
    "    print(\"IN collect_data_1.py: just made BaxterTestingEnv with env\")\n",
    "\n",
    "    agent = GreedyAgent(env)\n",
    "    if save_data:\n",
    "        if not os.path.exists(save_name):\n",
    "            os.makedirs(save_name)\n",
    "            os.makedirs(os.path.join(save_name,'view1'))\n",
    "            os.makedirs(os.path.join(save_name, 'view2'))\n",
    "        else:\n",
    "            shutil.rmtree(save_name)\n",
    "            os.makedirs(save_name)\n",
    "            os.makedirs(os.path.join(save_name, 'view1'))\n",
    "            os.makedirs(os.path.join(save_name, 'view2'))\n",
    "\n",
    "    print(\"Finished making dirs\")\n",
    "\n",
    "    total_steps = 0\n",
    "    success_log = []\n",
    "    buff_states = []\n",
    "    buff_actions = []\n",
    "    buff_dones = []\n",
    "    for n in range(FLAGS.num_episodes):\n",
    "        if print_on:\n",
    "            print('[Episode %d]'%n)\n",
    "\n",
    "        print(\"IN collect_data_1.py: start resetting BaxterEnv\")\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        cumulative_reward = 0.0\n",
    "        step_count = 0\n",
    "        ep_buff_states = []\n",
    "        ep_buff_actions = []\n",
    "        ep_buff_dones = []\n",
    "\n",
    "        while not done:\n",
    "            step_count += 1\n",
    "            print(\"Getting actions...\")\n",
    "            action = agent.get_action(obs)\n",
    "            new_obs, reward, done, _ = env.step(action)\n",
    "            if print_on:\n",
    "                print('action: %d / reward: %.2f'%(action, reward))\n",
    "            # print(step_count, 'steps \\t action: ', action, '\\t reward: ', reward)\n",
    "            cumulative_reward += reward\n",
    "\n",
    "            ep_buff_states.append(obs)\n",
    "            ep_buff_actions.append(action)\n",
    "            ep_buff_dones.append(int(done))\n",
    "            obs = new_obs\n",
    "            # obs1,obs2 = env.get_camera_image(env, [camera_pos], camera_rot_mat, arm='right',vis_on=False)\n",
    "\n",
    "            # list_of_view = ['frontview', 'birdview', 'agentview', 'rlview1', 'rlview2', 'eye_on_right_wrist', 'eye_in_hand', 'eye_on_left_wrist']\n",
    "            obs1 = np.array(obs[0])\n",
    "            obs2 = np.array(obs[1])\n",
    "            rescaled1 = (255.0*obs1[:,:,:3]).astype(np.uint8)\n",
    "            rescaled2 = (255.0 * obs2[:,:,:3]).astype(np.uint8)\n",
    "            im1 = Image.fromarray(rescaled1)\n",
    "            im2 = Image.fromarray(rescaled2)\n",
    "            im1.save(os.path.join(save_name, 'view1/'+str(n)+'_'+str(step_count)+'-view1.png'))\n",
    "            im2.save(os.path.join(save_name, 'view2/'+str(n)+'_'+str(step_count)+'-view2.png'))\n",
    "\n",
    "        success = bool(cumulative_reward >= 90)\n",
    "        success_log.append(int(success))\n",
    "\n",
    "        print(\"Finished saving images\")\n",
    "\n",
    "        # recording the trajectories\n",
    "        if success and save_data:\n",
    "            buff_states += ep_buff_states\n",
    "            buff_actions += ep_buff_actions\n",
    "            buff_dones += ep_buff_dones\n",
    "            total_steps += len(ep_buff_states)\n",
    "\n",
    "            print(\"Entering Pkl Phase\")\n",
    "\n",
    "            if not os.path.isdir(save_name):\n",
    "                os.makedirs(save_name)\n",
    "            if len(buff_states) >= FLAGS.max_buff:\n",
    "                f_list = os.listdir(save_name)\n",
    "                num_pickles = len([f for f in f_list if task in f])\n",
    "                save_num = num_pickles // 3\n",
    "                with open(os.path.join(save_name, task + '_s_%d.pkl'%save_num), 'wb') as f:\n",
    "                    pickle.dump(np.array(buff_states)[:FLAGS.max_buff], f)\n",
    "                with open(os.path.join(save_name, task + '_a_%d.pkl'%save_num), 'wb') as f:\n",
    "                    pickle.dump(np.array(buff_actions)[:FLAGS.max_buff], f)\n",
    "                with open(os.path.join(save_name, task + '_d_%d.pkl'%save_num), 'wb') as f:\n",
    "                    pickle.dump(np.array(buff_dones)[:FLAGS.max_buff], f)\n",
    "\n",
    "                print('---' * 10)\n",
    "                print(save_num, '-th file saved.')\n",
    "                print('action distribution:')\n",
    "                for a in range(max(env.action_size, max(buff_actions)+1)):\n",
    "                    print('%d: %.2f'%(a, list(buff_actions).count(a)/len(buff_actions)))\n",
    "                print('---' * 10)\n",
    "                print('current success rate:', np.mean(success_log))\n",
    "\n",
    "                buff_states = buff_states[FLAGS.max_buff:]\n",
    "                buff_actions = buff_actions[FLAGS.max_buff:]\n",
    "                buff_dones = buff_dones[FLAGS.max_buff:]\n",
    "                # buff_states, buff_actions = [], []\n",
    "\n",
    "        # print('success rate?:', np.mean(success_log))\n",
    "        print('Episode %d ends.'%(n+1), '( Total steps:', total_steps, ')')\n",
    "        print('Ep len:', step_count, 'steps.   Ep reward:', cumulative_reward)\n",
    "        print('success:', sum(success_log), ' ,   failure:', len(success_log)-sum(success_log))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f65b62c2518>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "env = gym.make('Breakout-v0') # insert your favorite environment\n",
    "render = lambda : plt.imshow(env.render(mode='rgb_array'))\n",
    "env.reset()\n",
    "render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def show_state(env, step=0, info=\"\"):\n",
    "    plt.figure(3)\n",
    "    plt.clf()\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    plt.title(\"%s | Step: %d %s\" % (env._spec.id,step, info))\n",
    "    plt.axis('off')\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "env = gym.make('Humanoid-v2')\n",
    "env.reset()\n",
    "for _ in range(100):\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    action = env.action_space.sample()\n",
    "    env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
